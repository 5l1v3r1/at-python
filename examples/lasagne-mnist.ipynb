{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is taken from here:\n",
    "http://deeplearning.net/tutorial/gettingstarted.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import academictorrents as at\n",
    "import cPickle, gzip\n",
    "import sys, os, time\n",
    "import numpy as np\n",
    "import theano, lasagne\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "##### Options ######\n",
    "model='mlp' # 'cnn' or 'mlp'\n",
    "num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mnist.pkl.gz\n",
      "10% [4 Mirrors 546KB/s]\n",
      "20% [3 Mirrors 541KB/s]\n",
      "30% [4 Mirrors 545KB/s]\n",
      "40% [7 Mirrors 546KB/s]\n",
      "50% [7 Mirrors 542KB/s]\n",
      "60% [8 Mirrors 622KB/s]\n",
      "70% [10 Mirrors 622KB/s]\n",
      "80% [12 Mirrors 1.6MB/s]\n",
      "90% [6 Mirrors 541KB/s]\n",
      "100%\n",
      "mnist.pkl.gz located at /home/joecohen/lasagne-mnist/mnist.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "#Download MNIST from Academic torrents\n",
    "f = at.get(\"323a0048d87ca79b68f12a6350a57776b6a3b7fb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "mnist = gzip.open(f, 'rb')\n",
    "train_set, validation_set, test_set = cPickle.load(mnist)\n",
    "mnist.close()\n",
    "\n",
    "X_train = train_set[0].reshape(-1, 1, 28, 28)\n",
    "y_train = train_set[1]\n",
    "X_val = validation_set[0].reshape(-1, 1, 28, 28)\n",
    "y_val = validation_set[1]\n",
    "X_test = test_set[0].reshape(-1, 1, 28, 28)\n",
    "y_test = test_set[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Label', 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e6fa890>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBB8IiOADARF8IKD/AWbmBOYfQIz/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1147b8510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label\", y_train[0])\n",
    "plt.imshow(X_train[0][0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Label', 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e926710>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e7d9b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label\", y_train[1])\n",
    "plt.imshow(X_train[1][0], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var=None):\n",
    "    # This creates an MLP of two hidden layers of 800 units each, followed by\n",
    "    # a softmax output layer of 10 units. It applies 20% dropout to the input\n",
    "    # data and 50% dropout to the hidden layers.\n",
    "\n",
    "    # Input layer, specifying the expected input shape of the network\n",
    "    # (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
    "    # linking it to the given Theano variable `input_var`, if any:\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 28, 28), input_var=input_var)\n",
    "\n",
    "    # Apply 20% dropout to the input data:\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "\n",
    "    # Add a fully-connected layer of 800 units, using the linear rectifier, and\n",
    "    # initializing weights with Glorot's scheme (which is the default anyway):\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # We'll now add dropout of 50%:\n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    # Another 800-unit layer:\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # 50% dropout again:\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "\n",
    "    # Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2_drop, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    # Each layer is linked to its incoming layer(s), so we only need to pass\n",
    "    # the output layer to give access to a network in Lasagne:\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(input_var=None):\n",
    "    # As a third model, we'll create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "\n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "    # This time we do not apply input dropout, as it tends to work less well\n",
    "    # for convolutional layers.\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    # Expert note: Lasagne provides alternative convolutional layers that\n",
    "    # override Theano's choice of which implementation to use; for details\n",
    "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
    "\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n"
     ]
    }
   ],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model (depending on first command line parameter)\n",
    "print(\"Building model and compiling functions...\")\n",
    "if model == 'mlp':\n",
    "    network = build_mlp(input_var)\n",
    "elif model == 'cnn':\n",
    "    network = build_cnn(input_var)\n",
    "else:\n",
    "    print(\"Unrecognized model type %r.\" % model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
